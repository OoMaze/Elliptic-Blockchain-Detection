{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix\n",
    "from lib.Elliptic_data import Get_data, get_Data, split_idx\n",
    "from lib.util import load_best_result, save_best_checkpoint\n",
    "from model.loss import FocalLoss\n",
    "from model.model import Net, GCNNet, GATNet, SimpleNet,EMA\n",
    "def mixup_data(x, alpha=1.0):\n",
    "    '''Compute the mixup data. Return mixed inputs, mixed target, and lambda'''\n",
    "    if alpha > 0.:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1.\n",
    "    batch_size = x.size()[0]\n",
    "    index = np.random.permutation(batch_size)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index,:]\n",
    "    return mixed_x.to(torch.float32)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Elliptic dataloader')\n",
    "#set\n",
    "parser.add_argument('--device', default='cpu', type=str, help='Choose the device to train, cpu | cuda:0')\n",
    "parser.add_argument('--mode', default='train', type=str, help='Choose the mode to use the model, train | test')\n",
    "parser.add_argument('--epoch', default=100, type=int)\n",
    "parser.add_argument('--step', default=None, type=int, help='if train all data, set None, else 1~49')\n",
    "#dataset\n",
    "parser.add_argument('--test_ratio', default=0.8, type=float)\n",
    "parser.add_argument('--seed', default=42, type=int, help='Set the spliting seeds')\n",
    "#model\n",
    "parser.add_argument('--mode_name',default='Net', type=str)\n",
    "parser.add_argument('--loss',default='BCE',type=str)\n",
    "parser.add_argument('--hid_dim',default=128, type=int)\n",
    "parser.add_argument('--f_att',default=True, type=bool,help='Feature Booster')\n",
    "parser.add_argument('--slices',default=3, type=int)\n",
    "parser.add_argument('--num_layer',default=1, type=int)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, edge_index, classified_idx, unclassified_idx, un_edge_index = Get_data(step=args.step, un=True, aug=True)\n",
    "if args.step is not None:\n",
    "    print('Setp:',args.step)\n",
    "input_Data = get_Data(data, edge_index)\n",
    "mixup_unx1= mixup_data(x=data[unclassified_idx], alpha=0.4)\n",
    "mixup_unx2= mixup_data(x=data[unclassified_idx], alpha=2)\n",
    "unlabel_Data1 = get_Data(mixup_unx1, un_edge_index)\n",
    "unlabel_Data2 = get_Data(mixup_unx2, un_edge_index)\n",
    "train_idx, valid_idx = split_idx(input_Data, classified_idx, args.test_ratio, args.seed)\n",
    "print('Get Data Ready, train shape {} | val shape {}'.format(len(train_idx), len(valid_idx)))\n",
    "device = torch.device(args.device)\n",
    "if args.loss == 'Focal':\n",
    "    criterion = FocalLoss(alpha=0.25)\n",
    "elif args.loss == 'BCE':\n",
    "    criterion = torch.nn.BCELoss()\n",
    "pretrain =  Net(dim_in=input_Data.x.shape[1], dim_hidden=args.hid_dim, slices=args.slices, num_layer=args.num_layer, f_att=args.f_att).to(device)\n",
    "pretrain.float()\n",
    "pretrain, _ = load_best_result(pretrain, args.mode_name)\n",
    "model = SimpleNet(dim_in=input_Data.x.shape[1], dim_hidden=args.hid_dim).to(device)\n",
    "model.float()\n",
    "\n",
    "ema_model = EMA(model,0.999)\n",
    "ema_model.register()\n",
    "best_loss = np.Inf\n",
    "input_Data, unlabel_Data1, unlabel_Data2 = input_Data.to(device), unlabel_Data1.to(device), unlabel_Data2.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.mode == 'train':\n",
    "    tea_loss_list = []\n",
    "    stu_loss_list = []\n",
    "    for epoch in range(1, args.epoch+1):\n",
    "        optimizer.zero_grad()\n",
    "        if epoch ==1:\n",
    "            un_out2 = pretrain(unlabel_Data2)\n",
    "            l_out = pretrain(input_Data)\n",
    "        else:\n",
    "            l_out = model(input_Data)\n",
    "        un_out1 = model(unlabel_Data1)\n",
    "        l_loss = criterion(l_out[train_idx].squeeze(), input_Data.y[train_idx])\n",
    "        un_loss = criterion(un_out1, un_out2)\n",
    "        loss = l_loss + un_loss\n",
    "        auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[train_idx], l_out[train_idx].detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema_model.update()\n",
    "        if epoch%5 == 0:\n",
    "            print(\"epoch: {:2d} - Student loss: {:.6f} - roc: {:.6f}\".format(epoch, loss.item(), auc))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            ema_model.apply_shadow()\n",
    "            un_out2 = model(unlabel_Data2)\n",
    "            l_out = model(input_Data)\n",
    "            un_loss = criterion(un_out1, un_out2)\n",
    "            auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[valid_idx], l_out[valid_idx].detach().cpu().numpy())\n",
    "            if epoch%5 == 0:\n",
    "                print(\"epoch: {:2d} - Teacher loss: {:.6f} - roc: {:.6f}\".format(epoch, un_loss.item(), auc))\n",
    "            if un_loss < best_loss:\n",
    "                best_loss = un_loss\n",
    "                best_epoch = epoch\n",
    "                save_best_checkpoint(model, best_epoch, 'Teacher')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    best_model, best_epoch = load_best_result(model, 'Teacher')\n",
    "    print('Best Model Load At {}'.format(best_epoch))\n",
    "except:\n",
    "    print('Load Model Fail!')\n",
    "\n",
    "preds = best_model(input_Data)\n",
    "preds = preds.detach().cpu().numpy()\n",
    "\n",
    "out_labels = preds > 0.5\n",
    "train_acc = accuracy_score(input_Data.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\n",
    "train_auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[train_idx], preds[train_idx])\n",
    "f1_train = f1_score(input_Data.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\n",
    "print(\"Train accuracy: {:.6f}\".format(train_acc))\n",
    "print(\"train AUC     : {:.6f}\".format(train_auc))\n",
    "print(\"F1 score      : {:.6f}\".format(f1_train))\n",
    "print('--------------------------')\n",
    "valid_auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[valid_idx], preds[valid_idx])\n",
    "valid_acc = accuracy_score(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\n",
    "f1_valid = f1_score(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\n",
    "print(\"Valid accuracy: {:.6f}\".format(valid_acc))\n",
    "print(\"Valid AUC     : {:.6f}\".format(valid_auc))\n",
    "print(\"F1 score      : {:.6f}\".format(f1_valid))\n",
    "print('--------------------------')\n",
    "f1_total = f1_score(input_Data.y.detach().cpu().numpy()[classified_idx], out_labels[classified_idx])\n",
    "print('Total F1 score: {:.6f}'.format(f1_total))\n",
    "print(confusion_matrix(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pretrain(input_Data)\n",
    "preds = preds.detach().cpu().numpy()\n",
    "\n",
    "out_labels = preds > 0.5\n",
    "train_acc = accuracy_score(input_Data.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\n",
    "train_auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[train_idx], preds[train_idx])\n",
    "f1_train = f1_score(input_Data.y.detach().cpu().numpy()[train_idx], out_labels[train_idx])\n",
    "print(\"Train accuracy: {:.6f}\".format(train_acc))\n",
    "print(\"train AUC     : {:.6f}\".format(train_auc))\n",
    "print(\"F1 score      : {:.6f}\".format(f1_train))\n",
    "print('--------------------------')\n",
    "valid_auc = roc_auc_score(input_Data.y.detach().cpu().numpy()[valid_idx], preds[valid_idx])\n",
    "valid_acc = accuracy_score(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\n",
    "f1_valid = f1_score(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx])\n",
    "print(\"Valid accuracy: {:.6f}\".format(valid_acc))\n",
    "print(\"Valid AUC     : {:.6f}\".format(valid_auc))\n",
    "print(\"F1 score      : {:.6f}\".format(f1_valid))\n",
    "print('--------------------------')\n",
    "f1_total = f1_score(input_Data.y.detach().cpu().numpy()[classified_idx], out_labels[classified_idx])\n",
    "print('Total F1 score: {:.6f}'.format(f1_total))\n",
    "print(confusion_matrix(input_Data.y.detach().cpu().numpy()[valid_idx], out_labels[valid_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
